{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trying to download 2024-05-30 data\n",
      "Downloaded Datasets/ZIPS\\2024-05-30.zip\n",
      "Renamed Datasets\\domain-names.txt to Datasets\\domain-names-2024-05-30.txt\n",
      "Extracted Datasets/ZIPS\\2024-05-30.zip to Datasets\n",
      "Trying to download 2024-05-31 data\n",
      "Downloaded Datasets/ZIPS\\2024-05-31.zip\n",
      "Renamed Datasets\\domain-names.txt to Datasets\\domain-names-2024-05-31.txt\n",
      "Extracted Datasets/ZIPS\\2024-05-31.zip to Datasets\n",
      "Trying to download 2024-06-01 data\n",
      "Downloaded Datasets/ZIPS\\2024-06-01.zip\n",
      "Renamed Datasets\\domain-names.txt to Datasets\\domain-names-2024-06-01.txt\n",
      "Extracted Datasets/ZIPS\\2024-06-01.zip to Datasets\n",
      "Trying to download 2024-06-02 data\n",
      "Downloaded Datasets/ZIPS\\2024-06-02.zip\n",
      "Renamed Datasets\\domain-names.txt to Datasets\\domain-names-2024-06-02.txt\n",
      "Extracted Datasets/ZIPS\\2024-06-02.zip to Datasets\n"
     ]
    }
   ],
   "source": [
    "import base64\n",
    "import requests\n",
    "import zipfile\n",
    "import os\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Function to download and extract CSV from a dynamically generated URL\n",
    "def download_and_extract_csv(start_date):\n",
    "    # Convert the start date to the required string format\n",
    "    str_start_date = start_date.strftime(\"%Y-%m-%d\")\n",
    "    print(\"Trying to download \" + str_start_date + \" data\")\n",
    "    \n",
    "    # Encode the date to base64\n",
    "    date_zip = str_start_date + \".zip\"\n",
    "    random_str = base64.b64encode(date_zip.encode(\"utf-8\")).decode(\"utf-8\")\n",
    "    \n",
    "    # Construct the URL\n",
    "    url = \"https://www.whoisds.com/whois-database/newly-registered-domains/\" + random_str + \"/nrd\"\n",
    "    \n",
    "    # Make the request to download the ZIP file\n",
    "    response = requests.get(url)\n",
    "    \n",
    "    # Check if the request was successful\n",
    "    if response.status_code == 200:\n",
    "        # Define paths\n",
    "        zip_folder = \"Datasets/ZIPS\"\n",
    "        extract_folder = \"Datasets\"\n",
    "        \n",
    "        # Ensure the ZIP folder exists\n",
    "        os.makedirs(zip_folder, exist_ok=True)\n",
    "        \n",
    "        # Save the ZIP file in the ZIPS folder\n",
    "        zip_filename = os.path.join(zip_folder, date_zip)\n",
    "        with open(zip_filename, 'wb') as f:\n",
    "            f.write(response.content)\n",
    "        print(f\"Downloaded {zip_filename}\")\n",
    "\n",
    "        # Extract the CSV file from the ZIP into the Datasets folder\n",
    "        with zipfile.ZipFile(zip_filename, 'r') as zip_ref:\n",
    "            zip_ref.extractall(extract_folder)  # Extracts all files in the ZIP to the Datasets directory\n",
    "        \n",
    "        # Rename the extracted domain-names.txt file to include the date\n",
    "        original_file = os.path.join(extract_folder, \"domain-names.txt\")\n",
    "        new_file = os.path.join(extract_folder, f\"domain-names-{str_start_date}.txt\")\n",
    "        if os.path.exists(original_file):\n",
    "            os.rename(original_file, new_file)\n",
    "            print(f\"Renamed {original_file} to {new_file}\")\n",
    "\n",
    "        print(f\"Extracted {zip_filename} to {extract_folder}\")\n",
    "\n",
    "    else:\n",
    "        print(f\"Failed to download data for {str_start_date}. Status code: {response.status_code}\")\n",
    "\n",
    "def get_latest_date_from_zips(zip_folder):\n",
    "    # List all files in the ZIP folder\n",
    "    files = os.listdir(zip_folder)\n",
    "    # Filter out files that don't match the date pattern\n",
    "    date_files = [f for f in files if f.endswith(\".zip\") and len(f) == 14]\n",
    "    \n",
    "    # Extract dates from filenames\n",
    "    dates = [datetime.strptime(f[:10], \"%Y-%m-%d\") for f in date_files]\n",
    "    \n",
    "    # Return the latest date or None if no dates found\n",
    "    return max(dates) if dates else None\n",
    "\n",
    "# Main script\n",
    "if __name__ == \"__main__\":\n",
    "    zip_folder = \"Datasets/ZIPS\"\n",
    "    latest_date = get_latest_date_from_zips(zip_folder)\n",
    "    \n",
    "    current_date = datetime.now().date()\n",
    "    \n",
    "    if latest_date:\n",
    "        # Increment the latest date by one day to get the next date\n",
    "        next_date = latest_date + timedelta(days=1)\n",
    "    else:\n",
    "        # If no date is found, set the default date to current date - 4\n",
    "        next_date = current_date - timedelta(days=4)\n",
    "    \n",
    "    # Loop to download and extract all missing dates up to the current date\n",
    "    while next_date < current_date:\n",
    "        download_and_extract_csv(next_date)\n",
    "        next_date += timedelta(days=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trying to download 2024-04-01 data\n",
      "Downloaded Datasets/ZIPS\\2024-04-01.zip\n"
     ]
    },
    {
     "ename": "BadZipFile",
     "evalue": "File is not a zip file",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mBadZipFile\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 62\u001b[0m\n\u001b[0;32m     60\u001b[0m next_date \u001b[38;5;241m=\u001b[39m start_date\n\u001b[0;32m     61\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m next_date \u001b[38;5;241m<\u001b[39m current_date:\n\u001b[1;32m---> 62\u001b[0m     \u001b[43mdownload_and_extract_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnext_date\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     63\u001b[0m     next_date \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m timedelta(days\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "Cell \u001b[1;32mIn[3], line 39\u001b[0m, in \u001b[0;36mdownload_and_extract_csv\u001b[1;34m(start_date)\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDownloaded \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mzip_filename\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     38\u001b[0m \u001b[38;5;66;03m# Extract the CSV file from the ZIP into the Datasets folder\u001b[39;00m\n\u001b[1;32m---> 39\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mzipfile\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mZipFile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mzip_filename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m zip_ref:\n\u001b[0;32m     40\u001b[0m     zip_ref\u001b[38;5;241m.\u001b[39mextractall(extract_folder)  \u001b[38;5;66;03m# Extracts all files in the ZIP to the Datasets directory\u001b[39;00m\n\u001b[0;32m     42\u001b[0m \u001b[38;5;66;03m# Rename the extracted domain-names.txt file to include the date\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\TANMAY\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\zipfile.py:1299\u001b[0m, in \u001b[0;36mZipFile.__init__\u001b[1;34m(self, file, mode, compression, allowZip64, compresslevel, strict_timestamps, metadata_encoding)\u001b[0m\n\u001b[0;32m   1297\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1298\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m-> 1299\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_RealGetContents\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1300\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m mode \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mx\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m   1301\u001b[0m         \u001b[38;5;66;03m# set the modified flag so central directory gets written\u001b[39;00m\n\u001b[0;32m   1302\u001b[0m         \u001b[38;5;66;03m# even if no files are added to the archive\u001b[39;00m\n\u001b[0;32m   1303\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_didModify \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\TANMAY\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\zipfile.py:1366\u001b[0m, in \u001b[0;36mZipFile._RealGetContents\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1364\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m BadZipFile(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFile is not a zip file\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   1365\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m endrec:\n\u001b[1;32m-> 1366\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m BadZipFile(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFile is not a zip file\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   1367\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdebug \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   1368\u001b[0m     \u001b[38;5;28mprint\u001b[39m(endrec)\n",
      "\u001b[1;31mBadZipFile\u001b[0m: File is not a zip file"
     ]
    }
   ],
   "source": [
    "import base64\n",
    "import requests\n",
    "import zipfile\n",
    "import os\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Function to download and extract CSV from a dynamically generated URL\n",
    "def download_and_extract_csv(start_date):\n",
    "    # Convert the start date to the required string format\n",
    "    str_start_date = start_date.strftime(\"%Y-%m-%d\")\n",
    "    print(\"Trying to download \" + str_start_date + \" data\")\n",
    "    \n",
    "    # Encode the date to base64\n",
    "    date_zip = str_start_date + \".zip\"\n",
    "    random_str = base64.b64encode(date_zip.encode(\"utf-8\")).decode(\"utf-8\")\n",
    "    \n",
    "    # Construct the URL\n",
    "    url = \"https://www.whoisds.com/whois-database/newly-registered-domains/\" + random_str + \"/nrd\"\n",
    "    \n",
    "    # Make the request to download the ZIP file\n",
    "    response = requests.get(url)\n",
    "    \n",
    "    # Check if the request was successful\n",
    "    if response.status_code == 200:\n",
    "        # Define paths\n",
    "        zip_folder = \"Datasets/ZIPS\"\n",
    "        extract_folder = \"Datasets\"\n",
    "        \n",
    "        # Ensure the ZIP folder exists\n",
    "        os.makedirs(zip_folder, exist_ok=True)\n",
    "        \n",
    "        # Save the ZIP file in the ZIPS folder\n",
    "        zip_filename = os.path.join(zip_folder, date_zip)\n",
    "        with open(zip_filename, 'wb') as f:\n",
    "            f.write(response.content)\n",
    "        print(f\"Downloaded {zip_filename}\")\n",
    "\n",
    "        # Extract the CSV file from the ZIP into the Datasets folder\n",
    "        with zipfile.ZipFile(zip_filename, 'r') as zip_ref:\n",
    "            zip_ref.extractall(extract_folder)  # Extracts all files in the ZIP to the Datasets directory\n",
    "        \n",
    "        # Rename the extracted domain-names.txt file to include the date\n",
    "        original_file = os.path.join(extract_folder, \"domain-names.txt\")\n",
    "        new_file = os.path.join(extract_folder, f\"domain-names-{str_start_date}.txt\")\n",
    "        if os.path.exists(original_file):\n",
    "            os.rename(original_file, new_file)\n",
    "            print(f\"Renamed {original_file} to {new_file}\")\n",
    "\n",
    "        print(f\"Extracted {zip_filename} to {extract_folder}\")\n",
    "\n",
    "    else:\n",
    "        print(f\"Failed to download data for {str_start_date}. Status code: {response.status_code}\")\n",
    "\n",
    "# Main script\n",
    "if __name__ == \"__main__\":\n",
    "    start_date = datetime(2024, 4, 1).date()\n",
    "    current_date = datetime.now().date()\n",
    "    \n",
    "    # Loop to download and extract all missing dates up to the current date\n",
    "    next_date = start_date\n",
    "    while next_date < current_date:\n",
    "        download_and_extract_csv(next_date)\n",
    "        next_date += timedelta(days=1)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
