{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempting to download: https://s.yimg.com/rz/p/yahoo_frontpage_en-US_s_f_p_bestfit_frontpage_2x.png\n",
      "Saved as PNG: url_1_images\\yahoo_frontpage_en-US_s_f_p_bestfit_frontpage_2x.png\n",
      "Downloaded: url_1_images\\yahoo_frontpage_en-US_s_f_p_bestfit_frontpage_2x.png\n",
      "Attempting to download: https://s.yimg.com/rz/p/yahoo_frontpage_en-US_s_f_w_bestfit_frontpage_2x.png\n",
      "Saved as PNG: url_1_images\\yahoo_frontpage_en-US_s_f_w_bestfit_frontpage_2x.png\n",
      "Downloaded: url_1_images\\yahoo_frontpage_en-US_s_f_w_bestfit_frontpage_2x.png\n",
      "Attempting to download: https://s.yimg.com/rz/p/yahoo_frontpage_en-US_s_f_p_bestfit_frontpage_2x.png\n",
      "Saved as PNG: url_1_images\\yahoo_frontpage_en-US_s_f_p_bestfit_frontpage_2x.png\n",
      "Downloaded: url_1_images\\yahoo_frontpage_en-US_s_f_p_bestfit_frontpage_2x.png\n",
      "Attempting to download: https://s.yimg.com/rz/p/yahoo_frontpage_en-US_s_f_w_bestfit_frontpage_2x.png\n",
      "Saved as PNG: url_1_images\\yahoo_frontpage_en-US_s_f_w_bestfit_frontpage_2x.png\n",
      "Downloaded: url_1_images\\yahoo_frontpage_en-US_s_f_w_bestfit_frontpage_2x.png\n",
      "Attempting to download: https://login.yahoo.com/account/js-reporting/?crumb=X87qiAcFYKttubuOMVzw&message=javascript_not_enabled&ref=%2F\n",
      "Failed to download https://login.yahoo.com/account/js-reporting/?crumb=X87qiAcFYKttubuOMVzw&message=javascript_not_enabled&ref=%2F: [Errno 2] No such file or directory: 'url_1_images\\\\'\n",
      "Image downloading process completed for https://login.yahoo.com/?.intl=us&done=https%3A%2F%2Fwww.yahoo.com%2F&add=1.\n",
      "Attempting to download: https://s.yimg.com/rz/p/yahoo_frontpage_en-US_s_f_p_bestfit_frontpage_2x.png\n",
      "Saved as PNG: url_2_images\\yahoo_frontpage_en-US_s_f_p_bestfit_frontpage_2x.png\n",
      "Downloaded: url_2_images\\yahoo_frontpage_en-US_s_f_p_bestfit_frontpage_2x.png\n",
      "Attempting to download: https://s.yimg.com/rz/p/yahoo_frontpage_en-US_s_f_w_bestfit_frontpage_2x.png\n",
      "Saved as PNG: url_2_images\\yahoo_frontpage_en-US_s_f_w_bestfit_frontpage_2x.png\n",
      "Downloaded: url_2_images\\yahoo_frontpage_en-US_s_f_w_bestfit_frontpage_2x.png\n",
      "Attempting to download: https://s.yimg.com/rz/p/yahoo_frontpage_en-US_s_f_p_bestfit_frontpage_2x.png\n",
      "Saved as PNG: url_2_images\\yahoo_frontpage_en-US_s_f_p_bestfit_frontpage_2x.png\n",
      "Downloaded: url_2_images\\yahoo_frontpage_en-US_s_f_p_bestfit_frontpage_2x.png\n",
      "Attempting to download: https://s.yimg.com/rz/p/yahoo_frontpage_en-US_s_f_w_bestfit_frontpage_2x.png\n",
      "Saved as PNG: url_2_images\\yahoo_frontpage_en-US_s_f_w_bestfit_frontpage_2x.png\n",
      "Downloaded: url_2_images\\yahoo_frontpage_en-US_s_f_w_bestfit_frontpage_2x.png\n",
      "Attempting to download: https://pub-bec2426b4a3f4b5aa714d43c72068106.r2.dev/account/js-reporting/?crumb=GDgQDF5uEfr&message=javascript_not_enabled&ref=%2F\n",
      "Failed to download https://pub-bec2426b4a3f4b5aa714d43c72068106.r2.dev/account/js-reporting/?crumb=GDgQDF5uEfr&message=javascript_not_enabled&ref=%2F: HTTP Status 404\n",
      "Image downloading process completed for https://pub-bec2426b4a3f4b5aa714d43c72068106.r2.dev/login.htm.\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import os\n",
    "import shutil\n",
    "from urllib.parse import urljoin, urlparse\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "\n",
    "def delete_directory_if_exists(directory):\n",
    "    if os.path.exists(directory):\n",
    "        shutil.rmtree(directory)\n",
    "\n",
    "def download_images_from_url(url, save_dir):\n",
    "    # Create the directory to save the images\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "    # Start a session to persist headers and cookies\n",
    "    session = requests.Session()\n",
    "    session.headers.update({\n",
    "        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.36'\n",
    "    })\n",
    "\n",
    "    # Fetch the HTML content\n",
    "    response = session.get(url)\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "    # Find all image tags\n",
    "    img_tags = soup.find_all('img')\n",
    "\n",
    "    # Extract image URLs and download them\n",
    "    for img in img_tags:\n",
    "        img_url = img.get('src')\n",
    "        \n",
    "        if img_url:\n",
    "            # If the URL is relative, make it absolute\n",
    "            img_url = urljoin(url, img_url)\n",
    "            \n",
    "            try:\n",
    "                # Verify if URL is correctly formed\n",
    "                parsed_url = urlparse(img_url)\n",
    "                if not parsed_url.scheme or not parsed_url.netloc:\n",
    "                    raise ValueError(f\"Invalid URL: {img_url}\")\n",
    "                \n",
    "                # Extract image name\n",
    "                img_name = os.path.join(save_dir, os.path.basename(parsed_url.path))\n",
    "                \n",
    "                # Log URL being downloaded\n",
    "                print(f\"Attempting to download: {img_url}\")\n",
    "                \n",
    "                # Download the image\n",
    "                img_response = session.get(img_url, allow_redirects=True)\n",
    "                if img_response.status_code == 200:\n",
    "                    with open(img_name, 'wb') as f:\n",
    "                        f.write(img_response.content)\n",
    "                    \n",
    "                    # Save the image as PNG if there is data\n",
    "                    image = Image.open(BytesIO(img_response.content))\n",
    "                    if image:\n",
    "                        png_name = os.path.splitext(img_name)[0] + '.png'\n",
    "                        image.save(png_name)\n",
    "                        print(f\"Saved as PNG: {png_name}\")\n",
    "                        \n",
    "                    print(f\"Downloaded: {img_name}\")\n",
    "                else:\n",
    "                    print(f\"Failed to download {img_url}: HTTP Status {img_response.status_code}\")\n",
    "            except Exception as e:\n",
    "                print(f\"Failed to download {img_url}: {e}\")\n",
    "\n",
    "    print(f\"Image downloading process completed for {url}.\")\n",
    "\n",
    "# URLs to download images from\n",
    "#url1 = actual \n",
    "#url2 = fake\n",
    "url1 = 'https://login.yahoo.com/?.intl=us&done=https%3A%2F%2Fwww.yahoo.com%2F&add=1'\n",
    "url2 = 'https://pub-bec2426b4a3f4b5aa714d43c72068106.r2.dev/login.htm'\n",
    "\n",
    "# Directories to save the images\n",
    "save_dir1 = \"url_1_images\"\n",
    "save_dir2 = \"url_2_images\"\n",
    "\n",
    "# Delete directories if they already exist\n",
    "delete_directory_if_exists(save_dir1)\n",
    "delete_directory_if_exists(save_dir2)\n",
    "\n",
    "# Download images from both URLs\n",
    "download_images_from_url(url1, save_dir1)\n",
    "download_images_from_url(url2, save_dir2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image yahoo_frontpage_en-US_s_f_p_bestfit_frontpage_2x.png is most similar to yahoo_frontpage_en-US_s_f_p_bestfit_frontpage_2x.png with a similarity score (Hamming distance) of 0\n",
      "Image yahoo_frontpage_en-US_s_f_w_bestfit_frontpage_2x.png is most similar to yahoo_frontpage_en-US_s_f_w_bestfit_frontpage_2x.png with a similarity score (Hamming distance) of 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\TANMAY\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\PIL\\Image.py:979: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "import imagehash\n",
    "\n",
    "# Directories containing the images\n",
    "dir1 = \"url_1_images\"\n",
    "dir2 = \"url_2_images\"\n",
    "\n",
    "# Get list of image files in both directories\n",
    "images_dir1 = [os.path.join(dir1, f) for f in os.listdir(dir1) if os.path.isfile(os.path.join(dir1, f))]\n",
    "images_dir2 = [os.path.join(dir2, f) for f in os.listdir(dir2) if os.path.isfile(os.path.join(dir2, f))]\n",
    "\n",
    "# Function to calculate the similarity between two images\n",
    "def calculate_similarity(image1, image2):\n",
    "    hash1 = imagehash.phash(image1)\n",
    "    hash2 = imagehash.phash(image2)\n",
    "    return hash1 - hash2  # Hamming distance\n",
    "\n",
    "# Compare each image in dir2 with all images in dir1\n",
    "results = {}\n",
    "for img2_path in images_dir2:\n",
    "    try:\n",
    "        img2 = Image.open(img2_path)\n",
    "    except Exception as e:\n",
    "        print(f\"Error opening image {img2_path}: {e}\")\n",
    "        continue\n",
    "    \n",
    "    best_match = None\n",
    "    lowest_distance = float('inf')\n",
    "    \n",
    "    for img1_path in images_dir1:\n",
    "        try:\n",
    "            img1 = Image.open(img1_path)\n",
    "        except Exception as e:\n",
    "            print(f\"Error opening image {img1_path}: {e}\")\n",
    "            continue\n",
    "        \n",
    "        distance = calculate_similarity(img1, img2)\n",
    "        if distance < lowest_distance:\n",
    "            lowest_distance = distance\n",
    "            best_match = img1_path\n",
    "    \n",
    "    if best_match:\n",
    "        results[img2_path] = (best_match, lowest_distance)\n",
    "\n",
    "# Print results\n",
    "for img2_path, (best_match, lowest_distance) in results.items():\n",
    "    print(f\"Image {os.path.basename(img2_path)} is most similar to {os.path.basename(best_match)} with a similarity score (Hamming distance) of {lowest_distance}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# whitelist image download\n",
    "# import requests\n",
    "# from bs4 import BeautifulSoup\n",
    "# import os\n",
    "# import shutil\n",
    "# from urllib.parse import urljoin, urlparse\n",
    "\n",
    "# def delete_directory_if_exists(directory):\n",
    "#     if os.path.exists(directory):\n",
    "#         shutil.rmtree(directory)\n",
    "\n",
    "# def download_images_from_url(url, save_dir):\n",
    "#     # Create the directory to save the images\n",
    "#     os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "#     # Start a session to persist headers and cookies\n",
    "#     session = requests.Session()\n",
    "#     session.headers.update({\n",
    "#         'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.36'\n",
    "#     })\n",
    "\n",
    "#     # Fetch the HTML content\n",
    "#     response = session.get(url)\n",
    "#     soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "#     # Find all image tags\n",
    "#     img_tags = soup.find_all('img')\n",
    "\n",
    "#     # Extract image URLs and download them\n",
    "#     for img in img_tags:\n",
    "#         img_url = img.get('src')\n",
    "        \n",
    "#         if img_url:\n",
    "#             # If the URL is relative, make it absolute\n",
    "#             img_url = urljoin(url, img_url)\n",
    "            \n",
    "#             try:\n",
    "#                 # Verify if URL is correctly formed\n",
    "#                 parsed_url = urlparse(img_url)\n",
    "#                 if not parsed_url.scheme or not parsed_url.netloc:\n",
    "#                     raise ValueError(f\"Invalid URL: {img_url}\")\n",
    "                \n",
    "#                 # Extract image name\n",
    "#                 img_name = os.path.join(save_dir, os.path.basename(parsed_url.path))\n",
    "                \n",
    "#                 # Log URL being downloaded\n",
    "#                 print(f\"Attempting to download: {img_url}\")\n",
    "                \n",
    "#                 # Download the image\n",
    "#                 img_response = session.get(img_url, allow_redirects=True)\n",
    "#                 if img_response.status_code == 200:\n",
    "#                     with open(img_name, 'wb') as f:\n",
    "#                         f.write(img_response.content)\n",
    "#                     print(f\"Downloaded: {img_name}\")\n",
    "#                 else:\n",
    "#                     print(f\"Failed to download {img_url}: HTTP Status {img_response.status_code}\")\n",
    "#             except Exception as e:\n",
    "#                 print(f\"Failed to download {img_url}: {e}\")\n",
    "\n",
    "#     print(f\"Image downloading process completed for {url}.\")\n",
    "\n",
    "# # URLs to download images from\n",
    "# urls = {\n",
    "#     \"crsorgi-govi.com\": \"https://crsorgi-govi.com/web/index.php/auth/index\",\n",
    "#     \"www.icicibank.com\": \"https://www.icicibank.com\",\n",
    "#     \"www.hdfcbank.com\": \"https://www.hdfcbank.com\",\n",
    "#     \"www.rbi.org.in\": \"https://www.rbi.org.in\",\n",
    "#     \"www.airtel.in\": \"https://www.airtel.in\",\n",
    "#     \"msme.gov.in\": \"https://msme.gov.in\",\n",
    "#     \"state.bihar.gov.in\": \"https://state.bihar.gov.in\",\n",
    "#     \"uidai.gov.in\": \"https://uidai.gov.in\",\n",
    "#     \"www.isro.gov.in\": \"https://www.isro.gov.in\",\n",
    "#     \"www.tatapower.com\": \"https://www.tatapower.com\",\n",
    "#     \"www.cowin.gov.in\": \"https://www.cowin.gov.in\",\n",
    "#     \"www.mohfw.gov.in\": \"https://www.mohfw.gov.in\",\n",
    "#     \"parivahan.gov.in\": \"https://parivahan.gov.in\",\n",
    "#     \"nciipc.gov.in\": \"https://nciipc.gov.in\",\n",
    "#     \"registration.ind.in\": \"https://registration.ind.in\",\n",
    "#     \"pmkusum.mnre.gov.in\": \"https://pmkusum.mnre.gov.in\",\n",
    "#     \"indianrailways.gov.in\": \"https://indianrailways.gov.in\",\n",
    "#     \"www.irctc.co.in\": \"https://www.irctc.co.in\",\n",
    "#     \"www.onlinesbi.sbi\":\"https://www.onlinesbi.sbi\"\n",
    "# }\n",
    "\n",
    "# # Download images from all URLs\n",
    "# for domain, url in urls.items():\n",
    "#     save_dir = f\"{domain}_images\"\n",
    "#     delete_directory_if_exists(save_dir)\n",
    "#     download_images_from_url(url, save_dir)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
